{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "this is a demo to use Mamba model based on below code and paper\n",
        "\n",
        "Src Code ::\n",
        "https://github.com/state-spaces/mamba\n",
        "\n",
        "PAPER with SSM ::\n",
        "https://arxiv.org/pdf/2312.00752.pdf\n"
      ],
      "metadata": {
        "id": "cUR-7GhxZEUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install causal-conv1d==1.0.0\n",
        "!pip install mamba-ssm==1.0.1\n",
        "#!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEY0XJsJXh5J",
        "outputId": "eccaa088-1605-4695-a05b-8c07b55e9809"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: causal-conv1d==1.0.0 in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from causal-conv1d==1.0.0) (2.1.0+cu121)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from causal-conv1d==1.0.0) (23.2)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from causal-conv1d==1.0.0) (1.11.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d==1.0.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d==1.0.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d==1.0.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d==1.0.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d==1.0.0) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d==1.0.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d==1.0.0) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->causal-conv1d==1.0.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->causal-conv1d==1.0.0) (1.3.0)\n",
            "Requirement already satisfied: mamba-ssm==1.0.1 in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mamba-ssm==1.0.1) (2.1.0+cu121)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mamba-ssm==1.0.1) (23.2)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from mamba-ssm==1.0.1) (1.11.1.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from mamba-ssm==1.0.1) (0.7.0)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (from mamba-ssm==1.0.1) (2.1.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from mamba-ssm==1.0.1) (4.35.2)\n",
            "Requirement already satisfied: causal-conv1d in /usr/local/lib/python3.10/dist-packages (from mamba-ssm==1.0.1) (1.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm==1.0.1) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm==1.0.1) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm==1.0.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm==1.0.1) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm==1.0.1) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm==1.0.1) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm==1.0.1) (0.20.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm==1.0.1) (1.23.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm==1.0.1) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm==1.0.1) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm==1.0.1) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm==1.0.1) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm==1.0.1) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm==1.0.1) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->mamba-ssm==1.0.1) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm==1.0.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm==1.0.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm==1.0.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm==1.0.1) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->mamba-ssm==1.0.1) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ADm4AePVbnI-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fix PyTorch Issue\n",
        "Look here:\n",
        "https://github.com/pytorch/pytorch/issues/107960"
      ],
      "metadata": {
        "id": "p6Oe7F2-u-L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!export LC_ALL=\"en_US.UTF-8\"\n",
        "!export LD_LIBRARY_PATH=\"/usr/lib64-nvidia\"\n",
        "!export LIBRARY_PATH=\"/usr/local/cuda/lib64/stubs\"\n",
        "!ldconfig /usr/lib64-nvidia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SF37NJUuZYMx",
        "outputId": "144d8ccf-867b-4b59-8690-a873ce742434"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n6jImH8MXmUK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use MAMBA pretrained model (state-spaces/mamba-2.8b)"
      ],
      "metadata": {
        "id": "KJKFuqFqae39"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CPM0PoWuXebF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "from transformers import AutoTokenizer\n",
        "from mamba_ssm.models.mixer_seq_simple import MambaLMHeadModel\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n",
        "model = MambaLMHeadModel.from_pretrained(os.path.expanduser(\"state-spaces/mamba-2.8b\"), device=\"cuda\", dtype=torch.float16).to(device)"
      ],
      "metadata": {
        "id": "BuxWDTa-XfC2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9e603e7-558a-49a4-d08d-43c4feaff0d3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer(\"What is the meaning of life\", return_tensors=\"pt\")\n",
        "input_ids = tokens.input_ids.to(device=\"cuda\")\n",
        "max_length = input_ids.shape[1] + 80\n",
        "fn = lambda: model.generate(\n",
        "        input_ids=input_ids, max_length=max_length, cg=True,\n",
        "        return_dict_in_generate=True, output_scores=True,\n",
        "        enable_timing=False, temperature=0.1, top_k=10, top_p=0.2,)\n",
        "out = fn()\n",
        "print(tokenizer.decode(out[0][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVSkhGwAcYLp",
        "outputId": "5a6074e1-c81a-41f9-8d34-3dfb9eaecd0a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the meaning of life?\n",
            "\n",
            "What is the meaning of life?\n",
            "\n",
            "What is the meaning of life?\n",
            "\n",
            "What is the meaning of life?\n",
            "\n",
            "What is the meaning of life?\n",
            "\n",
            "What is the meaning of life?\n",
            "\n",
            "What is the meaning of life?\n",
            "\n",
            "What is the meaning of life?\n",
            "\n",
            "What is the meaning of life?\n",
            "\n",
            "What is the meaning of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "-rEV_tWsyWAF",
        "outputId": "3273a70b-03e1-4b7a-c9cc-7d1fbca9434f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MambaLMHeadModel(\n",
            "  (backbone): MixerModel(\n",
            "    (embedding): Embedding(50280, 2560)\n",
            "    (layers): ModuleList(\n",
            "      (0-63): 64 x Block(\n",
            "        (mixer): Mamba(\n",
            "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
            "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
            "          (act): SiLU()\n",
            "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
            "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
            "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
            "        )\n",
            "        (norm): RMSNorm()\n",
            "      )\n",
            "    )\n",
            "    (norm_f): RMSNorm()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=2560, out_features=50280, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v9-4nEq6yVyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del tokenizer\n",
        "del model"
      ],
      "metadata": {
        "id": "4VXK5MBxcz1-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Chat\n",
        "\n",
        "https://github.com/havenhq/mamba-chat/tree/main\n",
        "\n",
        "https://huggingface.co/datasets/HuggingFaceH4/ultrachat_200k\n",
        "\n"
      ],
      "metadata": {
        "id": "TP-4PoPmb6sc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from mamba_ssm.models.mixer_seq_simple import MambaLMHeadModel\n",
        "\n",
        "device = \"cuda\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"havenhq/mamba-chat\")\n",
        "tokenizer.eos_token = \"<|endoftext|>\"\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.chat_template = AutoTokenizer.from_pretrained(\"HuggingFaceH4/zephyr-7b-beta\").chat_template\n",
        "\n",
        "model = MambaLMHeadModel.from_pretrained(\"havenhq/mamba-chat\", device=\"cuda\", dtype=torch.float16)\n"
      ],
      "metadata": {
        "id": "R_kxXFLPcvPl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c9ede60-dae8-48ab-9632-1e4bf8396974"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = []\n",
        "user_message = \"\"\"\n",
        "What is the date for announcement\n",
        "On August 10 said that its arm JSW Neo Energy has agreed to buy a portfolio of 1753 mega watt renewable energy generation capacity from Mytrah Energy India Pvt Ltd for Rs 10,530 crore.\n",
        " \"\"\"\n",
        "\n",
        "messages.append(dict(role=\"user\",content=user_message))\n",
        "input_ids = tokenizer.apply_chat_template(messages, return_tensors=\"pt\", add_generation_prompt=True).to(\"cuda\")\n",
        "out = model.generate(input_ids=input_ids, max_length=2000, temperature=0.9, top_p=0.7, eos_token_id=tokenizer.eos_token_id)\n",
        "decoded = tokenizer.batch_decode(out)\n",
        "messages.append(dict(role=\"assistant\",content=decoded[0].split(\"<|assistant|>\\n\")[-1]))\n",
        "print(\"Model:\", decoded[0].split(\"<|assistant|>\\n\")[-1])"
      ],
      "metadata": {
        "id": "kno8rLGwdSgG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09d16580-cbef-4c41-d30e-f56ed64107fc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: The date for announcement of the deal between JSW Neo Energy and Mytrah Energy India Pvt Ltd is August 10, 2019.<|endoftext|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = []\n",
        "user_message = \"\"\"\n",
        "What is the acquirer\n",
        "On August 10 said that its arm JSW Neo Energy has agreed to buy a portfolio of 1753 mega watt renewable energy generation capacity from Mytrah Energy India Pvt Ltd for Rs 10,530 crore.\n",
        " \"\"\"\n",
        "\n",
        "messages.append(dict(role=\"user\",content=user_message))\n",
        "input_ids = tokenizer.apply_chat_template(messages, return_tensors=\"pt\", add_generation_prompt=True).to(\"cuda\")\n",
        "out = model.generate(input_ids=input_ids, max_length=2000, temperature=0.9, top_p=0.7, eos_token_id=tokenizer.eos_token_id)\n",
        "decoded = tokenizer.batch_decode(out)\n",
        "messages.append(dict(role=\"assistant\",content=decoded[0].split(\"<|assistant|>\\n\")[-1]))\n",
        "print(\"Model:\", decoded[0].split(\"<|assistant|>\\n\")[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-YGMYz-d4y0",
        "outputId": "5fccac40-0dfd-4cbb-af3f-e6d585809206"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: The acquirer is JSW Neo Energy, which is a subsidiary of JSW Energy.<|endoftext|>\n"
          ]
        }
      ]
    }
  ]
}